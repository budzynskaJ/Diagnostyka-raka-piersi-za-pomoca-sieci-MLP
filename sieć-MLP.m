%% Import data from text file
% Script for importing data from the following text file:
%
%    filename: C:\Users\jbudz\Desktop\studia\VI SEM\SNB\Breast Cancer Coimbra_MLR\dataR2.csv
%
% Auto-generated by MATLAB on 27-Apr-2022 18:14:49

%% Set up the Import Options and import the data
opts = delimitedTextImportOptions("NumVariables", 10);

% Specify range and delimiter
opts.DataLines = [2, Inf];
opts.Delimiter = ",";

% Specify column names and types
opts.VariableNames = ["Age", "BMI", "Glucose", "Insulin", "HOMA", "Leptin", "Adiponectin", "Resistin", "MCP1", "Classification"];
opts.VariableTypes = ["double", "double", "double", "double", "double", "double", "double", "double", "double", "double"];

% Specify file level properties
opts.ExtraColumnsRule = "ignore";
opts.EmptyLineRule = "read";

% Import the data
dataR2 = readtable("C:\Users\jbudz\Desktop\studia\VI SEM\SNB\Breast Cancer Coimbra_MLR\dataR2.csv", opts);


%% Clear temporary variables
clear opts


%% Normalizacja danych
dataR2N = normalize(dataR2, 'range'); 

%% Podział zbioru na trenujące i testujące
c = cvpartition(size(dataR2,1),'Holdout',0.3); % podział danych w stosunku 7:3
Ptrain = dataR2N(c.training, :); % zbiór trenujący 
Ptest = dataR2N(c.test,:); % zbiór testujący

%% training and testing

% training

Xwej = [Ptrain.Age.'; Ptrain.BMI.'; Ptrain.Glucose.'; Ptrain.Insulin.'; ...
    Ptrain.HOMA.'; Ptrain.Resistin.'; Ptrain.MCP1.'];  % wektor cech wejściowych  

OUT = [Ptrain.Classification.']; % wektor cech wyjściowych

epoch = 24000; % liczba epok sieci (iteracje)
eta = 0.07; % współczynnik trenujący
neurons_wej = size(Xwej,1); % neurony w warstwie wejściowej
neurons1 = 5; %neurony w wartswie ukrytej

W1 = rand(neurons1, neurons_wej+1); % macierz wag warstwy ukrytej
Wex = rand(1, neurons1+1); % macierz wag warstwy wyjściowej 

ind = []; % tablica indeksów (kolejnych iteracji programu)
MSE = []; % tablica błędów średniokwadratowych
sumMSErr = 0; % wartość początkowa błędu średniokwadratowego
bias = 1; % wartość współczynnika BIAS

N = length(Xwej); % liczba instancji zbioru trenującego

for step = 1:epoch
    
    for i = 1: N
        
        % Feedforward
        exFunc1 = W1 * [Xwej(:,i); bias]; % pobudzenie neuronów I warstwy ukrytej
        actFunc1 = logsig(exFunc1); % funkcja aktywacji I warstwy ukrytej
        y.est = Wex * [actFunc1; bias]; % estymowane wyjście neuronów warstwy
                                        % wyjściowej
        
        % Backpropagation
        y.correct = OUT(1,i); % poprawne wyjście neuronów warstwy wyjściowej
        error = (y.correct - y.est); % błąd dla konkretnej instancji
        % zapis błędów każdej iteracji do tabel
        Error(i) = error; 
        Yest(i) = y.est;
        Ycorrect(i) = y.correct;
        
        %sygnał błedu warstwy ukrytej
        errorW1 = dlogsig(exFunc1, actFunc1).*Wex(:,1:neurons1)' * error;
        
        Wex = Wex + eta * error * [actFunc1; bias]'; % aktualizacja wagi 
                                                        % warstwy wyjściowej
        W1 = W1 + eta * errorW1 * [Xwej(:,i); bias]'; % aktualizacja wagi
                                                      % warstwy ukrytej
        
        sumMSErr = sumMSErr +  (1/N) * error.^2;  % błąd średniokwadratowy
        ind(step) = step;
        MSE(step) = sumMSErr/step; % średnia wartość błędu średniokwadratowego
                                    % dla poszczególnych iteracji
         
    end
    
end


% testing

Testwej = [Ptest.Age.'; Ptest.BMI.'; Ptest.Glucose.'; Ptest.Insulin.'; ...
    Ptest.HOMA.'; Ptest.Resistin.'; Ptest.MCP1.']; % wektor cech wejściowych 
                                                    % ze zbioru testującego 
                                        
OUT = [Ptest.Classification.']; % wektor poprawnych wyjść ze zbioru testującego

count = 0; % numer testowanej pacjentki

M = length(Testwej); % długość zbioru testujacego

for j = 1:M
    count = count +1;               
    exFuncT1 = W1 * [Testwej(:,j); bias]; % pobudzenie neuronów warstwy ukrytej
    actFuncT1 = logsig(exFuncT1); % funkcja aktywacji
        
    out.est(count) = Wex * [actFuncT1; bias]; % estymowane wyjście neuronów
                                                % warstwy wyjściowej
    out.correct(count) = OUT(1,j); % poprawne wyjście neuronó warstwy wyjściowej
    inp(count) = j;
    
    if (out.est(count) < 0.5)
        out_ap.est(count) = 0;
    else
        out_ap.est(count) = 1;
    end

end

% wykresy

subplot(1,2,1);
plot(ind, MSE, "LineWidth", 1);
xlabel("liczba iteracji");
ylabel("wartość błędu średniokwadratowego");
title("Wykres błędu średniokwadratowego uczenia sieci");
subplot(1,2,2);
plot(inp, out.est, 'o', 'Color', 'r');
hold on;
plot(inp, out.correct, 'x', 'Color', 'b');
xlabel("pacjentka");
ylabel("wynik");
legend("diagnoza estymowana", "diagnoza prawidłowa");
title("Wykres poprawności identyfikacji choroby");


% tablica pomyłek

TP = numel(find(out.correct == 1 & out_ap.est == out.correct));
TN = numel(find(out.correct == 0 & out_ap.est == out.correct));

FP = numel(find(out.correct == 0 & out_ap.est ~= out.correct));
FN = numel(find(out.correct == 1 & out_ap.est ~= out.correct));

tab = table([TP; FN], [FP; TN], 'RowNames', {'dodatni'; 'ujemny'}, 'VariableNames', {'dodatni', 'ujemny'})


% czułość testu - zdolność do wykrywania osób rzeczywiście chorych
format bank; % wyświetlanie wyników z dokładnością do dwóch miejsc po przecinku
sens = (TP/(TP + FN)) * 100

% swoistość testu - zdolność testu do prawidłowego wykluczenia osób bez choroby
spec = (TN/(TN + FP)) * 100

% wartość predykcyjna dodatnia
PPV = (TP/(TP + FP))*100

% wartość predykcyjna ujemna
NPV = (TN/(TN + FN))*100

% dokładność testu
ACC = ((TN + TP)/height(Ptest))*100
